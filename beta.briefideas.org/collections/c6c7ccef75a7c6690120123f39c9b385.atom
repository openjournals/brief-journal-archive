<?xml version="1.0" encoding="UTF-8"?>
<feed xml:lang="en-US" xmlns="http://www.w3.org/2005/Atom">
  <id>tag:beta.briefideas.org,2005:/collections/c6c7ccef75a7c6690120123f39c9b385</id>
  <link rel="alternate" type="text/html" href="https://beta.briefideas.org"/>
  <link rel="self" type="application/atom+xml" href="https://beta.briefideas.org/collections/c6c7ccef75a7c6690120123f39c9b385.atom"/>
  <title>Journal of Brief Ideas: Collection DS@LHC</title>
  <updated>2016-02-26T21:06:17Z</updated>
  <entry>
    <id>tag:beta.briefideas.org,2005:Idea/242</id>
    <published>2015-09-29T20:59:58Z</published>
    <updated>2015-11-24T16:25:36Z</updated>
    <link rel="alternate" type="text/html" href="https://beta.briefideas.org/ideas/9806c0ed3b27a42cf4be89374fbc6ae5"/>
    <title>Modify and run other people's research code in your browser</title>
    <doi>http://dx.doi.org/10.5281/zenodo.31598</doi>
    <content type="html">Science makes progress by reusing results and building on them. For research software this is pretty hard (the people writing it often do not have the time to make slick installers like big libraries do). As a result there is not as much reuse as there could be. With [`everware`](//github.com/everware/everware) we are changing this.

With `everware` you can edit and run code from a git repository with one click, in your browser. This significantly reduces the barrier to entry for trying out other people's code on a whim. As a result you will try out and decide to reuse other people's code more often, instead of rolling your own. Furthermore, if reuse is possible, reproducibility comes for free.

Interest in big discoveries like the Higgs boson is massive, imagine how many lay-people would love to be able to run (parts of) the analysis software that discovered the Higgs.

As the author of a research code all you have to do for your repository to be `everware`-ready is provide a `Dockerfile` that describes how to setup all the dependencies. Once this is done other's can launch your code from their browser and experiment with it.

`Everware` builds on [github](//github.com), [docker](//docker.io) and [project jupyter](//jupyter.org). It started as a project at the [CERN webfest 2015](//webfest.web.cern.ch/). You can find [project everware](//github.com/everware/everware) on github.</content>
    <author>
      <name>Head, Tim</name>
    </author>
  </entry>
  <entry>
    <id>tag:beta.briefideas.org,2005:Idea/263</id>
    <published>2015-12-25T11:46:30Z</published>
    <updated>2015-12-31T05:14:48Z</updated>
    <link rel="alternate" type="text/html" href="https://beta.briefideas.org/ideas/918f1ccab7dc2c79b11022a82e098689"/>
    <title>Data Science and High Energy Physics collaboration enforcement by Higher Education Institutions </title>
    <doi>http://dx.doi.org/10.5281/zenodo.35718</doi>
    <content type="html">Data Science @ LHC workshops have been intensifying cooperation in the Data Science (DS) and High Energy Physics (HEP) professional communities. The need for such cooperation risen substantially in recent years, since it requires combining competences in HEP of everyone who are working in different experimental groups of the LHC experiment, as well as in Data Mining (DM) successfully applying up-to-date techniques of machine learning and big data management in various non-physics fields. One way for such systematic combining competences could be a join of DM and HEP experts (with ensuring adequate immersion in the complex and specific area of HEP, quite a number of involved professionals, methodological support of processes and their continuous development) on the Higher Education Institution platform with appropriate research and/or educational initiatives - Master and PHD educational programs, joint scientific laboratories etc. It allows combining in the same university environment researchers, teaching staff, students who are interested in DM and HEP and have suitable background. It could provide stable ideas and staff exchange and development. It would be useful to launch such an initiative (perhaps on the basis of the LHC) as a working group (or its sector) including interested authoritative universities. The working group would discuss methods and formats for scientific and educational projects for DM and HEP in higher education, the possibilities of financial support for such projects, joint activities for their development with the support of the LHC community etc.</content>
    <author>
      <name>Zamyatin, Alexander</name>
    </author>
  </entry>
  <entry>
    <id>tag:beta.briefideas.org,2005:Idea/278</id>
    <published>2016-01-20T10:40:16Z</published>
    <updated>2016-02-02T18:17:28Z</updated>
    <link rel="alternate" type="text/html" href="https://beta.briefideas.org/ideas/b082ab5e63d400dab21a3ae8ffe4c2aa"/>
    <title>Supervised and unsupervised machine learning approach to the CMS data quality monitoring</title>
    <doi>http://dx.doi.org/10.5281/zenodo.45024</doi>
    <content type="html">The CMS experiment at the LHC is one of the biggest and most complex general purpose detectors ever built. The constant monitoring of the data quality is vital to guarantee a proper and efficient operation of the detector and reliable physics results. The choice of the key variables to be monitored by shifters and experts in the Data Quality Monitoring (DQM) framework relies on the expertise of the detector operators. The use of supervised machine learning techniques in the process, to be trained with the data collected and scrutinised in Run1, would allow saving a considerable fraction of the manpower in the data quality assessment process. From recent data taking emerged clearly that, with the constant evolution of the detector hardware and software, not all the corners are covered by the current DQM system in the phase space of the failures. The approach to data quality with unsupervised feature learning techniques, would highlight the presence of unforeseen patterns and anomalies while taking data. A fast feedback to experts and the chance to predict failures before they manifest themselves, would make the CMS collaboration save data usable for the final analyses and money at the same time.</content>
    <author>
      <name>De Guio, Federico</name>
    </author>
  </entry>
</feed>
